{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsfQNtShD9nC",
        "outputId": "36ec6d43-d086-4a55-a564-f69aa8068dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile hello_cuda.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// CUDA kernel - runs on GPU\n",
        "// __global__ means this function is called from CPU but runs on GPU\n",
        "__global__ void vectorAdd(float *a, float *b, float *c, int n) {\n",
        "    // Calculate global thread ID\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Make sure we don't go out of bounds\n",
        "    if (tid < n) {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000000;  // 1 million elements\n",
        "    size_t bytes = n * sizeof(float);\n",
        "\n",
        "    // Allocate memory on host (CPU)\n",
        "    float *h_a = (float*)malloc(bytes);\n",
        "    float *h_b = (float*)malloc(bytes);\n",
        "    float *h_c = (float*)malloc(bytes);\n",
        "\n",
        "    // Initialize arrays on host\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = 1.0f;\n",
        "        h_b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on device (GPU)\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    float milliseconds = 0;\n",
        "\n",
        "    // Time: Copy data from host to device\n",
        "    printf(\"\\n=== Timing Breakdown ===\\n\");\n",
        "    cudaEventRecord(start);\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Host to Device transfer: %.3f ms\\n\", milliseconds);\n",
        "\n",
        "    // Setup kernel launch parameters\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    printf(\"\\nLaunching kernel with %d blocks of %d threads\\n\",\n",
        "           blocksPerGrid, threadsPerBlock);\n",
        "\n",
        "    // Time: Kernel execution\n",
        "    cudaEventRecord(start);\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Kernel execution: %.3f ms\\n\", milliseconds);\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Kernel launch error: %s\\n\", cudaGetErrorString(err));\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Make sure kernel is complete\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Time: Copy result back to host\n",
        "    cudaEventRecord(start);\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Device to Host transfer: %.3f ms\\n\", milliseconds);\n",
        "\n",
        "    // Verify result\n",
        "    bool success = true;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        if (h_c[i] != 3.0f) {\n",
        "            printf(\"Error at index %d: expected 3.0, got %f\\n\", i, h_c[i]);\n",
        "            success = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (success) {\n",
        "        printf(\"\\nSuccess! Added %d elements on GPU\\n\", n);\n",
        "    }\n",
        "\n",
        "    printf(\"======================\\n\");\n",
        "\n",
        "    // Free CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "/*\n",
        " * To compile and run:\n",
        " *\n",
        " * LOCAL:\n",
        " * nvcc -o hello_cuda hello_cuda.cu\n",
        " * ./hello_cuda\n",
        " *\n",
        " * GOOGLE COLAB:\n",
        " * !nvcc -arch=sm_75 -o hello_cuda hello_cuda.cu\n",
        " * !./hello_cuda\n",
        " *\n",
        " * (Use -arch=sm_75 for Tesla T4, -arch=sm_37 for K80, -arch=sm_60 for P100)\n",
        " *\n",
        " * Key concepts demonstrated:\n",
        " * 1. __global__ keyword for kernel functions\n",
        " * 2. Memory allocation with cudaMalloc()\n",
        " * 3. Data transfer with cudaMemcpy()\n",
        " * 4. Kernel launch syntax: kernel<<<blocks, threads>>>()\n",
        " * 5. Thread ID calculation: blockIdx.x * blockDim.x + threadIdx.x\n",
        " * 6. Synchronization with cudaDeviceSynchronize()\n",
        " * 7. Memory cleanup with cudaFree() and free()\n",
        " * 8. Timing with CUDA events\n",
        " * 9. Error checking with cudaGetLastError()\n",
        " */"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o hello_cuda hello_cuda.cu\n",
        "!./hello_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0nd-tY1EQOU",
        "outputId": "95da1bc4-41d3-487b-83c7-d4f5c687a7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Timing Breakdown ===\n",
            "Host to Device transfer: 3.875 ms\n",
            "\n",
            "Launching kernel with 3907 blocks of 256 threads\n",
            "Kernel execution: 0.191 ms\n",
            "Device to Host transfer: 3.264 ms\n",
            "\n",
            "Success! Added 1000000 elements on GPU\n",
            "======================\n"
          ]
        }
      ]
    }
  ]
}